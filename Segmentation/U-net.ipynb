{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"U-net.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6izVaL7JvQHO","colab_type":"text"},"source":["*   Author : Ziang Xu\n","*   Student number : 180104048\n","*   Code : U-net model construction, training and testing."]},{"cell_type":"code","metadata":{"id":"2ZYY71s7LNCc","colab_type":"code","colab":{}},"source":["# Google Colaboratory carry Google drive.\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X5v1MCAVLi2K","colab_type":"code","colab":{}},"source":["# Enter the segmentation task directory.\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"drive/ML/segmentation/\")\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wy5il_ywMKp8","colab_type":"code","colab":{}},"source":["# Model building.\n","import os\n","from skimage.transform import resize\n","from skimage.io import imsave\n","import numpy as np\n","from keras.models import Model\n","from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint\n","from keras import backend as K\n","from keras.optimizers import SGD\n","K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n","\n","img_rows = 224\n","img_cols = 224\n","\n","smooth = 1\n","def get_unet(pretrained_weights=None):\n","    '''\n","    Set Input layer for 224x224\n","\n","    '''\n","    inputs = Input((img_rows, img_cols,1))\n","    '''\n","    Down-sampling path.Each block consists 2 conv layers and 1 maxpooling layer.\n","    \n","    '''\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n","    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n","    '''\n","    Up-simpling path and skip connection.    \n","  \n","    '''\n","    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n","    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n","    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n","\n","    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n","    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n","    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n","\n","    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n","    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n","    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n","\n","    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n","    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n","    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n","\n","    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n","\n","    model = Model(inputs=[inputs], outputs=[conv10])\n","\n","    model.compile(optimizer=Adam(lr=1e-4), loss =dice_coef_loss , metrics = [dice_coef])\n","\n","    if (pretrained_weights):\n","        model.load_weights(pretrained_weights)\n","\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"74tmPBzfl9h8","colab_type":"code","colab":{}},"source":["model=get_unet()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RGUlOOQ1Pdwo","colab_type":"code","colab":{}},"source":["# Custom loss function.\n","def dice_coef(y_true, y_pred):\n","    y_true_f = K.flatten(y_true)\n","    y_pred_f = K.flatten(y_pred)\n","    intersection = K.sum(y_true_f * y_pred_f)\n","    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n","\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return 1-dice_coef(y_true, y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qt9li1I5MZpa","colab_type":"code","colab":{}},"source":["# Store the training dataset in .npy format for easy recall.\n","import os\n","import numpy as np\n","from skimage.io import imsave, imread\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","data_path = 'data/' # Setting path\n","image_rows = 512\n","image_cols = 512\n","def create_train_data():\n","    train_data_path = os.path.join(data_path, 'resize_train/Image') # Training file path\n","    train_data_Label_path = os.path.join(data_path, 'resize_train/Label') # Mask file path\n","    images = os.listdir(train_data_path)\n","    total = len(images)\n","    imgs = np.ndarray((total,image_rows, image_cols), dtype=np.uint8)\n","    imgs_mask = np.ndarray((total,image_rows, image_cols), dtype=np.uint8)\n","    i = 0\n","    print('Creating training images...')\n","    for image_name in images:\n","        img = imread(os.path.join(train_data_path, image_name), as_grey=True)\n","        img_mask = imread(os.path.join(train_data_Label_path, image_name), as_grey=True)\n","        \n","        img = img_to_array([img])\n","        img_mask = img_to_array([img_mask])\n","       \n","        imgs[i] = img\n","        imgs_mask[i] = img_mask\n","        if i % 100 == 0:\n","            print('Done: {0}/{1} images'.format(i, total))\n","        i += 1\n","    print('Loading done.')\n","    np.save('imgs_train.npy', imgs)\n","    np.save('imgs_mask_train.npy', imgs_mask)\n","    print('Saving to .npy files done.')\n","\n","create_train_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DdoN5OJJ1Wej","colab_type":"code","colab":{}},"source":["import pandas as pd\n","pd.Series(imgs_mask_train[1].reshape((1,-1))[0]).describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsR4kXJAw54R","colab_type":"code","colab":{}},"source":["def preprocess(imgs):\n","    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n","    for i in range(imgs.shape[0]):\n","        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n","\n","    imgs_p = imgs_p[..., np.newaxis]\n","    return imgs_p"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ioqOznijMbFA","colab_type":"code","colab":{}},"source":["# Read data\n","import numpy as np\n","imgs_train = np.load('imgs_train.npy')\n","imgs_mask_train = np.load('imgs_mask_train.npy')\n","imgs_train = preprocess(imgs_train)\n","imgs_mask_train = preprocess(imgs_mask_train)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOHOf_qfRZjm","colab_type":"code","colab":{}},"source":["# Normalized dataset\n","imgs_train = imgs_train.astype('float32')\n","imgs_train /=255.0\n","mean = np.mean(imgs_train)  # mean for data centering \n","imgs_train -= mean\n","imgs_mask_train = imgs_mask_train.astype('float32')\n","imgs_mask_train /= 255.0 # scale masks to [0, 1]\n","model = get_unet()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxMKQ2wfVwns","colab_type":"code","colab":{}},"source":["# Setting checkpoint\n","model_checkpoint = ModelCheckpoint('unet_weights.h5', monitor='val_loss',verbose=1, save_best_only=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qV45077-WC2y","colab_type":"code","colab":{}},"source":["# Model training.\n","history=model.fit(imgs_train, imgs_mask_train, batch_size=20, nb_epoch=200, verbose=1, shuffle=True,\n","              validation_split=0.2,\n","              callbacks=[model_checkpoint])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oa-mgeFV5Nfj","colab_type":"code","colab":{}},"source":["# Draw a graph of accuracy and loss functions.\n","from matplotlib import pyplot as plt\n","print(history.history.keys())\n","\n","# summarize history for accuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpZ-A9FFNhYQ","colab_type":"code","colab":{}},"source":["# Store the testing dataset in .npy format for easy recall.\n","import os\n","import numpy as np\n","from skimage.io import imsave, imread\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","data_path = 'data/'\n","\n","def create_test_data():\n","    test_data_path = os.path.join(data_path, 'test_small/Image') #训练文件路径\n","   \n","    images = os.listdir(test_data_path)\n","    total = len(images)\n","    imgs = np.ndarray((total,img_rows, img_cols), dtype=np.uint8)\n","    \n","    i = 0\n","    print('Creating training images...')\n","    for image_name in images:\n","        img_id = int(image_name.split('.')[0])\n","        img = imread(os.path.join(test_data_path, image_name), as_grey=True)\n","        \n","        img = np.array([img])\n","        \n","        \n","       \n","        imgs[i] = img\n","        \n","        if i % 100 == 0:\n","            print('Done: {0}/{1} images'.format(i, total))\n","        i += 1\n","    print('Loading done.')\n","    np.save('imgs_test.npy', imgs)\n","    \n","    print('Saving to .npy files done.')\n","\n","create_test_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-TEYjY4JOa7d","colab_type":"code","colab":{}},"source":["# Loading dataset.\n","import numpy as np\n","imgs_test = np.load('imgs_test.npy')\n","# imgs_id_test = np.load('imgs_id_test.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5lWTMegsXTSE","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","# model=load_model('unet_weights.h5')\n","model = get_unet('model/unet_weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IT0O4woAxyIH","colab_type":"code","colab":{}},"source":["imgs_test = preprocess(imgs_test)\n","imgs_test = imgs_test.astype('float32')\n","imgs_test /= 255."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FaBTzUiIymT_","colab_type":"code","colab":{}},"source":["# Model prediction/.\n","imgs_mask_test = model.predict(imgs_test, verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HsFv2M3Mz7v9","colab_type":"code","colab":{}},"source":["np.save('imgs_mask_test.npy', imgs_mask_test)\n","# imgs_mask_test = np.load('imgs_mask_test.npy')\n","imgs_id_test=np.load('imgs_id_test.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fk2b_VkEfPza","colab_type":"code","colab":{}},"source":["# Convert test data from arrays to  mask images.\n","from data import *\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","def save_img():\n","\t\tprint(\"array to image\")\n","\t\timgs = imgs_mask_test\n","\t\tfor i in range(imgs.shape[0]):\n","\t\t\timg = imgs[i]\n","      \n","\t\t\timg = array_to_img(img)\n","\t\t\timg.save(\"data/results/results_UNET/%d.jpg\"%(i))\n","save_img()"],"execution_count":0,"outputs":[]}]}