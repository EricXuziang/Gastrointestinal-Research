{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test-vgg.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"drwYf8KjgC9O","colab_type":"text"},"source":["*   Author : Ziang Xu\n","*   Student number : 180104048\n","*   Code : Vgg-16 model construction, training and testing.\n","*   Grad-CAM Visualization.\n","      "]},{"cell_type":"code","metadata":{"id":"bhGycEM6-C7a","colab_type":"code","colab":{}},"source":["# Google Colaboratory carry Google drive.\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XSVSDnF6-iUy","colab_type":"code","colab":{}},"source":["# Enter the classification task directory.\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"drive/ML/classification/\")\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PHGh9XkC2czD","colab_type":"code","colab":{}},"source":["'''\n","Visual task requires Keras, a fixed version of tensorflow, \n","but colab is automatically reset every day. So we need to reconfigure the version.\n","'''\n","!pip show keras\n","!pip show tensorflow\n","!pip show keras-vis"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKhlDq_j3BKj","colab_type":"code","colab":{}},"source":["!pip uninstall keras\n","!pip uninstall tensorflow\n","!pip uninstall keras-vis"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEsQJ6ZO3Bys","colab_type":"code","colab":{}},"source":["!pip install tensorflow==1.12\n","!pip install keras==2.2.4\n","!pip install git+https://github.com/raghakot/keras-vis.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j4am8r_i-15k","colab_type":"code","colab":{}},"source":["# Read dataset\n","import os\n","import numpy as np\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt\n","images=[]\n","labels=[]\n","def read_image(imageName):\n","    im = Image.open(imageName).convert('RGB')\n","    data = np.array(im)\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zakjlquo_Ws3","colab_type":"code","colab":{}},"source":["# Read there are several folders in the dataset.\n","text = os.listdir('./resize_data')\n","# Save the name of the image in the folder and its corresponding folder to the corresponding list.\n","for textPath in text:\n","    for fn in os.listdir(os.path.join('resize_data', textPath)):\n","        if fn.endswith('.jpg'):\n","            fd = os.path.join('./resize_data', textPath, fn)\n","            images.append(read_image(fd))\n","            labels.append(textPath)\n","            \n","X = np.array(images)\n","y = np.array(list(map(int, labels))) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"STADbr89AwSj","colab_type":"code","colab":{}},"source":["# Split dataset to 0.8 for training and 0.2 for testing.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tod8WaZVC3FF","colab_type":"code","colab":{}},"source":["# [0],dyed-lifted-polyps\n","# [1],dyed-resection-margins\n","# [2],esophagitis\n","# [3],normal-cecum\n","# [4],normal-pylorus\n","# [5],normal-z-line\n","# [6],polyps\n","# [7],ulcerative-colitis\n","plt.imshow(X_train[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2YjIu8mb7En","colab_type":"code","colab":{}},"source":["# Normalized dataset\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","from keras.utils import np_utils\n","Y_train = np_utils.to_categorical(y_train, 8)\n","Y_test = np_utils.to_categorical(y_test, 8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kUYA2m-C7XH","colab_type":"code","colab":{}},"source":["print(X_train.shape)\n","print(Y_train.shape)\n","print(X_test.shape)\n","print(Y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfQ2dVJ3T1-7","colab_type":"code","colab":{}},"source":["# Fine-tuning technique is used to build model.\n","from keras.applications.vgg16 import VGG16\n","\n","from keras.layers import Input\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.models import Model\n","from keras.optimizers import SGD\n","# Load model pre-training weights.\n","model_vgg = VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n","for layer in model_vgg.layers:\n","    layer.trainable = False\n","# Remove the fully connected layer and join the fully connected layer that belongs to us.   \n","model = Flatten(name='flatten')(model_vgg.output)\n","model = Dense(4096, activation='relu', name='fc1')(model)\n","model = Dense(4096, activation='relu', name='fc2')(model)\n","model = Dropout(0.5)(model)\n","model = Dense(8, activation='softmax')(model)\n","model_vgg16 = Model(inputs=model_vgg.input, outputs=model, name='vgg16')\n","\n","\n","\n","model_vgg16.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9gUysXLidD6I","colab_type":"code","colab":{}},"source":["# Set the callback to calculate the accuracy of each training.\n","import numpy\n","from keras.callbacks import Callback\n","from sklearn.metrics import f1_score, precision_score, recall_score\n","\n","\n","class Metrics(Callback):\n","    def on_train_begin(self, logs={}):\n","        self.val_f1s = []\n","        self.val_recalls = []\n","        self.val_precisions = []\n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        val_predict = (numpy.asarray(self.model.predict(\n","            self.validation_data[0]))).round()\n","        val_targ = self.validation_data[1]\n","        _val_f1 = f1_score(val_targ, val_predict,average='macro')\n","        _val_recall = recall_score(val_targ, val_predict,average='macro')\n","        _val_precision = precision_score(val_targ, val_predict,average='macro')\n","        self.val_f1s.append(_val_f1)\n","        self.val_recalls.append(_val_recall)\n","        self.val_precisions.append(_val_precision)\n","        print(_val_f1,_val_precision,_val_recall)\n","        return\n","metrics = Metrics()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1yQ1qkd0syP3","colab_type":"code","colab":{}},"source":["def precision(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + K.epsilon())\n","    return precision\n","\n","def recall(y_true, y_pred):\n","    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","    recall = true_positives / (possible_positives + K.epsilon())\n","    return recall\n","\n","def fbeta_score(y_true, y_pred, beta=1):\n","    if beta < 0:\n","        raise ValueError('The lowest choosable beta is zero (only precision).')\n","\n","    # If there are no true positives, fix the F score at 0 like sklearn.\n","    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n","        return 0\n","\n","    p = precision(y_true, y_pred)\n","    r = recall(y_true, y_pred)\n","    bb = beta ** 2\n","    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n","    return fbeta_score\n","\n","def fmeasure(y_true, y_pred):\n","    return fbeta_score(y_true, y_pred, beta=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IkSqQePHKaQM","colab_type":"code","colab":{}},"source":["# Customize the optimizer and compile the model.\n","import keras\n","opt_sgd = keras.optimizers.SGD(\n","                lr=1e-3\n","                , decay=1e-9\n","                , momentum=0.9\n","                , nesterov=False\n","            )\n","model.compile(\n","    loss='categorical_crossentropy'\n","    , optimizer=opt_sgd\n","    , metrics=[precision,recall,fbeta_score]\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jG78nPkZKgDc","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","model_checkpoint = ModelCheckpoint('vgg_16.h5', monitor='loss', verbose=1, save_best_only=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1yp5eGHrX0C8","colab_type":"code","colab":{}},"source":["# Training\n","print('Training begin')\n","history=model.fit(X_train, Y_train, batch_size=50, epochs=1,\n","          validation_data=(X_test, Y_test),callbacks=[metrics])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mwtV2k4bm5Lu","colab_type":"code","colab":{}},"source":["# Draw a graph of accuracy and loss functions.\n","print(history.history.keys())\n","\n","# summarize history for accuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P4r969J6nA1_","colab_type":"code","colab":{}},"source":["# Model saving and loading.\n","model_vgg16.save('model1.h5')\n","from keras.models import load_model\n","model=load_model('vgg-Bilinearnet.h5')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9Nf3z-VtVRM","colab_type":"code","colab":{}},"source":["from keras.utils import plot_model\n","plot_model(model,to_file='WRN.png',show_shapes=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lwdeFAVWgYJj","colab_type":"code","colab":{}},"source":["# Model evaluation\n","scores = model.evaluate(X_test, Y_test)\n","print('Test score:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kjsqBwLumrYJ","colab_type":"code","colab":{}},"source":["# Other evaluation methods\n","from sklearn import metrics\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-_w-3ba_oA5C","colab_type":"code","colab":{}},"source":["y_pred=model.predict(X_test)\n","y_true=Y_test\n","y_pred=np.argmax(y_pred, axis=1)\n","y_true=np.argmax(y_true, axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AoHOF26Gms3u","colab_type":"code","colab":{}},"source":["metrics.precision_score(y_true, y_pred,average='weighted')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ga-zniWyoc-U","colab_type":"code","colab":{}},"source":["accuracy_score(y_true, y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S2_bRAMkpPqh","colab_type":"code","colab":{}},"source":["metrics.recall_score(y_true, y_pred,average='weighted')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUDBjhTbpqdW","colab_type":"code","colab":{}},"source":["metrics.f1_score(y_true, y_pred,average='macro')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFpVNtN6p5V5","colab_type":"code","colab":{}},"source":["conf_arr=confusion_matrix(y_true, y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o5erwFHBqLHs","colab_type":"code","colab":{}},"source":["target_names = ['0', '1', '2','3','4','5','6','7']\n","print(classification_report(y_true, y_pred, target_names=target_names))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Q_LtUiPwpon","colab_type":"code","colab":{}},"source":["!pip install scikit-plot\n","import scikitplot as skplt\n","plot = skplt.metrics.plot_confusion_matrix(y_true, y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HAiJDBp-YM-I","colab_type":"code","colab":{}},"source":["# Model visualization\n","from keras.applications import VGG16\n","from vis.utils import utils\n","from keras import activations\n","\n","from vis.utils import utils\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (18,6)\n","\n","layer_idx = utils.find_layer_idx(model, 'dense_1')\n","\n","# Swap softmax with linear\n","model.layers[layer_idx].activation = activations.linear\n","model = utils.apply_modifications(model)\n","\n","img1 = utils.load_img('image/1.jpg', target_size=(224, 224))\n","img2 = utils.load_img('image/2.jpg', target_size=(224, 224))\n","img3 = utils.load_img('image/3.jpg', target_size=(224, 224))\n","img4 = utils.load_img('image/4.jpg', target_size=(224, 224))\n","img5 = utils.load_img('image/5.jpg', target_size=(224, 224))\n","\n","f,ax=plt.subplots(1,5)\n","ax[0].imshow(img1)\n","ax[1].imshow(img2)\n","ax[2].imshow(img3)\n","ax[3].imshow(img4)\n","ax[4].imshow(img5)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-auYOczdt-1","colab_type":"code","colab":{}},"source":["img6 = utils.load_img('image/6.jpg', target_size=(224, 224))\n","img7 = utils.load_img('image/7.jpg', target_size=(224, 224))\n","img8 = utils.load_img('image/8.jpg', target_size=(224, 224))\n","img9 = utils.load_img('image/9.jpg', target_size=(224, 224))\n","img10 = utils.load_img('image/10.jpg', target_size=(224, 224))\n","\n","f,ax=plt.subplots(1,5)\n","ax[0].imshow(img6)\n","ax[1].imshow(img7)\n","ax[2].imshow(img8)\n","ax[3].imshow(img9)\n","ax[4].imshow(img10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9O547IzFzpS","colab_type":"code","colab":{}},"source":["from vis.visualization import visualize_saliency, overlay\n","from vis.utils import utils\n","from keras import activations\n","\n","# Utility to search for layer index by name. \n","# Alternatively we can specify this as -1 since it corresponds to the last layer.\n","layer_idx = utils.find_layer_idx(model, 'dense_1')\n","\n","f, ax = plt.subplots(1,2)\n","for i, img in enumerate([img1, img2]): \n","    # 0 is the imagenet index corresponding to `dyed-lifted-polyps`\n","    grads = visualize_saliency(model, layer_idx, filter_indices=0, seed_input=img)\n","    \n","    # visualize grads as heatmap\n","    ax[i].imshow(grads, cmap='jet')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b5CaJoubTkab","colab_type":"code","colab":{}},"source":["for modifier in ['guided', 'relu']:\n","    plt.figure()\n","    f, ax = plt.subplots(1, 2)\n","    plt.suptitle(modifier)\n","    for i, img in enumerate([img1, img2]):   \n","        # 0 is the imagenet index corresponding to `dyed-lifted-polyps`\n","        grads = visualize_saliency(model, layer_idx, filter_indices=0, \n","                                   seed_input=img, backprop_modifier=modifier)\n","        # Lets overlay the heatmap onto original image.    \n","        ax[i].imshow(grads, cmap='jet')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6I_G0DwnHTN","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.cm as cm\n","from vis.visualization import visualize_cam\n","\n","for modifier in [None, 'guided', 'relu']:\n","    plt.figure()\n","    f, ax = plt.subplots(1, 2)\n","    plt.suptitle(\"vanilla\" if modifier is None else modifier)\n","    for i, img in enumerate([img1, img2]):  \n","        # 0 is the imagenet index corresponding to `dyed-lifted-polyps`\n","        grads = visualize_cam(model, layer_idx, filter_indices=0, \n","                              seed_input=img, backprop_modifier=modifier)        \n","        # Lets overlay the heatmap onto original image.    \n","        jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n","        ax[i].imshow(overlay(jet_heatmap, img))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y_DKC7lcV77C","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.cm as cm\n","from vis.visualization import visualize_cam\n","\n","for modifier in [None, 'guided', 'relu']:\n","    plt.figure()\n","    f, ax = plt.subplots(1, 2)\n","    plt.suptitle(\"vanilla\" if modifier is None else modifier)\n","    for i, img in enumerate([img3, img4]):  \n","        # 1 is the imagenet index corresponding to `dyed-resection-margins`\n","        grads = visualize_cam(model, layer_idx, filter_indices=1, \n","                              seed_input=img, backprop_modifier=modifier)        \n","        # Lets overlay the heatmap onto original image.    \n","        jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n","        ax[i].imshow(overlay(jet_heatmap, img))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g6uZV8-HTdwg","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.cm as cm\n","from vis.visualization import visualize_cam\n","\n","for modifier in ['guided']:\n","    plt.figure()\n","    f, ax = plt.subplots(1, 2)\n","    plt.suptitle(\"vanilla\" if modifier is None else modifier)\n","    for i, img in enumerate([img5, img6]):  \n","        # 2 is the imagenet index corresponding to `esophagitis`\n","        grads = visualize_cam(model, layer_idx, filter_indices=2, \n","                              seed_input=img, backprop_modifier=modifier)        \n","        # Lets overlay the heatmap onto original image.    \n","        jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n","        ax[i].imshow(overlay(jet_heatmap, img))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wX_17hxlUPq2","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.cm as cm\n","from vis.visualization import visualize_cam\n","\n","for modifier in ['guided']:\n","    plt.figure()\n","    f, ax = plt.subplots(1, 2)\n","    plt.suptitle(\"vanilla\" if modifier is None else modifier)\n","    for i, img in enumerate([img7, img8]):  \n","        # 6 is the imagenet index corresponding to `polyps`\n","        grads = visualize_cam(model, layer_idx, filter_indices=6, \n","                              seed_input=img, backprop_modifier=modifier)        \n","        # Lets overlay the heatmap onto original image.    \n","        jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n","        ax[i].imshow(overlay(jet_heatmap, img))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XkMoQ_MfUYio","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.cm as cm\n","from vis.visualization import visualize_cam\n","\n","for modifier in ['guided']:\n","    plt.figure()\n","    f, ax = plt.subplots(1,1)\n","    plt.suptitle(label[y])\n","    \n","    # 7 is the imagenet index corresponding to 'ulcerative-colitis'\n","    grads = visualize_cam(model, layer_idx, filter_indices=7, \n","                              seed_input=img9, backprop_modifier=modifier)        \n","    # Lets overlay the heatmap onto original image.    \n","    jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n","    ax.imshow(overlay(jet_heatmap, img9))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWqirhFIfEHi","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"3JudV83oA_a9","colab_type":"code","colab":{}},"source":["from keras.preprocessing import image\n","import numpy as np\n","from keras.utils.np_utils import *\n","\n","# Model prediction.\n","file_path='image/1.jpg' \n","img=image.load_img(file_path,target_size=(224,224))\n","x=image.img_to_array(img)\n","x=np.expand_dims(x,axis=0)\n","\n","\n","y=model.predict(x,verbose=1)\n","\n","y=y.argmax(axis=-1)\n","\n","label=['dyed-lifted-polyps','dyed-resection-margins','esophagitis','normal-cecum',\n","       'normal-pylorus','normal-z-line','polyps','ulcerative-colitis']\n","label=np.array(label)\n","\n","print(y,label[y])"],"execution_count":0,"outputs":[]}]}