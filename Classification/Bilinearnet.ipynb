{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bilinearnet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"IxrlRVf8tqeD","colab_type":"text"},"source":["*   Author : Ziang Xu\n","*   Student number : 180104048\n","*   Code : Bilinearnet model construction, training and testing."]},{"cell_type":"code","metadata":{"id":"1aw8EeKsuA9F","colab_type":"code","colab":{}},"source":["# Google Colaboratory carry Google drive\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xueIX7hJuJdR","colab_type":"code","colab":{}},"source":["# Enter the classification task directory\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"drive/ML/classification/\")\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"leED-ejvukA0","colab_type":"code","colab":{}},"source":["# Read dataset\n","import os\n","import numpy as np\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt\n","images=[]\n","labels=[]\n","def read_image(imageName):\n","    im = Image.open(imageName).convert('RGB')\n","    data = np.array(im)\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OMvkHIgcukm5","colab_type":"code","colab":{}},"source":["# Read there are several folders in the dataset.\n","text = os.listdir('./resize_data')\n","# Save the name of the image in the folder and its corresponding folder to the corresponding list.\n","for textPath in text:\n","    for fn in os.listdir(os.path.join('resize_data', textPath)):\n","        if fn.endswith('.jpg'):\n","            fd = os.path.join('./resize_data', textPath, fn)\n","            i=0\n","            print(i)\n","            i=i+1\n","            images.append(read_image(fd))\n","            labels.append(textPath)\n","            \n","X = np.array(images)\n","y = np.array(list(map(int, labels))) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UjObF78SuoDV","colab_type":"code","colab":{}},"source":["# Split dataset to 0.8 for training and 0.2 for testing.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=30)\n","# Normalized dataset\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","from keras.utils import np_utils\n","Y_train = np_utils.to_categorical(y_train, 8)\n","Y_test = np_utils.to_categorical(y_test, 8)\n","print(X_train.shape)\n","print(Y_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lmz3q9CQ_p9K","colab_type":"code","colab":{}},"source":["# Model building\n","import math\n","import time\n","import sys\n","import os\n","import random\n","import pickle\n","\n","import numpy as np\n","\n","import keras\n","import keras.layers\n","import keras.applications\n","import keras.backend\n","import keras.preprocessing.image\n","import keras.utils\n","import tensorflow as tf\n","\n","import cv2\n","import PIL\n","import PIL.Image\n","import matplotlib.pyplot as plt\n","from keras.initializers import glorot_normal\n","\n","def outer_product(x):\n","    '''\n","    calculate outer-products of 2 tensors\n","    assuming each of which has shape = (size_minibatch, total_pixels, size_filter)\n","    '''\n","    return keras.backend.batch_dot(\n","                x[0]\n","                , x[1]\n","                , axes=[1,1]\n","            ) / x[0].get_shape().as_list()[1] \n","\n","def signed_sqrt(x):\n","    '''\n","    calculate element-wise signed square root\n","\n","    '''\n","    return keras.backend.sign(x) * keras.backend.sqrt(keras.backend.abs(x) + 1e-9)\n","\n","def L2_norm(x, axis=-1):\n","    '''\n","    calculate L2-norm\n","    \n","    '''\n","    return keras.backend.l2_normalize(x, axis=axis)\n","\n","\n","def build_model(\n","    size_heigth=224\n","    ,size_width=224\n","    ,no_class=8\n","    ,no_last_layer_backbone=17\n","    \n","    ,name_optimizer=\"sgd\"\n","    ,rate_learning=1.0\n","    ,rate_decay_learning=0.0\n","    ,rate_decay_weight=0.0\n","    \n","    ,name_initializer=\"glorot_normal\"\n","    ,name_activation_logits=\"softmax\"\n","    ,name_loss=\"categorical_crossentropy\"\n","\n","    ,flg_debug=False\n","    ,**kwargs\n","):\n","    \n","    keras.backend.clear_session()\n","    \n","    print(\"-------------------------------\")\n","    print(\"parameters:\")\n","    for key, val in locals().items():\n","        if not val == None and not key == \"kwargs\":\n","            print(\"\\t\", key, \"=\",  val)\n","    print(\"-------------------------------\")\n","    \n","     \n","    ### load pre-trained model\n","    tensor_input = keras.layers.Input(shape=[size_heigth,size_width,3])\n","    model_detector = keras.applications.vgg16.VGG16(\n","                            input_tensor=tensor_input\n","                            , include_top=False\n","                            , weights='imagenet'\n","                        )\n","    \n","\n","     \n","    ### bilinear pooling\n","\n","    # extract features from detector\n","    x_detector = model_detector.layers[no_last_layer_backbone].output\n","    shape_detector = model_detector.layers[no_last_layer_backbone].output_shape\n","    if flg_debug:\n","        print(\"shape_detector : {}\".format(shape_detector))\n","\n","    # extract features from extractor , same with detector for symmetry DxD model\n","    shape_extractor = shape_detector\n","    x_extractor = x_detector\n","    if flg_debug:\n","        print(\"shape_extractor : {}\".format(shape_extractor))\n","        \n","    \n","    # rehape to (minibatch_size, total_pixels, filter_size)\n","    x_detector = keras.layers.Reshape(\n","            [\n","                shape_detector[1] * shape_detector[2] , shape_detector[-1]\n","            ]\n","        )(x_detector)\n","    if flg_debug:\n","        print(\"x_detector shape after rehsape ops : {}\".format(x_detector.shape))\n","        \n","    x_extractor = keras.layers.Reshape(\n","            [\n","                shape_extractor[1] * shape_extractor[2] , shape_extractor[-1]\n","            ]\n","        )(x_extractor)\n","    if flg_debug:\n","        print(\"x_extractor shape after rehsape ops : {}\".format(x_extractor.shape))\n","        \n","        \n","    # outer products of features, output shape=(minibatch_size, filter_size_detector*filter_size_extractor)\n","    x = keras.layers.Lambda(outer_product)(\n","        [x_detector, x_extractor]\n","    )\n","    if flg_debug:\n","        print(\"x shape after outer products ops : {}\".format(x.shape))\n","        \n","        \n","    # rehape to (minibatch_size, filter_size_detector*filter_size_extractor)\n","    x = keras.layers.Reshape([shape_detector[-1]*shape_extractor[-1]])(x)\n","    if flg_debug:\n","        print(\"x shape after rehsape ops : {}\".format(x.shape))\n","        \n","        \n","    # signed square-root \n","    x = keras.layers.Lambda(signed_sqrt)(x)\n","    if flg_debug:\n","        print(\"x shape after signed-square-root ops : {}\".format(x.shape))\n","        \n","    # L2 normalization\n","    x = keras.layers.Lambda(L2_norm)(x)\n","    if flg_debug:\n","        print(\"x shape after L2-Normalization ops : {}\".format(x.shape))\n","\n","\n","\n","    \n","    ### attach FC-Layer\n","\n","    if name_initializer != None:\n","            name_initializer = eval(name_initializer+\"()\")\n","            \n","    x = keras.layers.Dense(\n","            units=no_class\n","            ,kernel_regularizer=keras.regularizers.l2(rate_decay_weight)\n","            ,kernel_initializer=name_initializer\n","        )(x)\n","    if flg_debug:\n","        print(\"x shape after Dense ops : {}\".format(x.shape))\n","    tensor_prediction = keras.layers.Activation(name_activation_logits)(x)\n","    if flg_debug:\n","        print(\"prediction shape : {}\".format(tensor_prediction.shape))\n","\n","        \n","\n","  \n","    ### compile model\n","    model_bilinear = keras.models.Model(\n","                        inputs=[tensor_input]\n","                        , outputs=[tensor_prediction]\n","                    )\n","    \n","    \n","    # fix pre-trained weights\n","    for layer in model_detector.layers:\n","        layer.trainable = False\n","        \n","        \n","    # define optimizers\n","    opt_adam = keras.optimizers.adam(\n","                    lr=rate_learning\n","                    , decay=rate_decay_learning\n","                )\n","    opt_rms = keras.optimizers.RMSprop(\n","                    lr=rate_learning\n","                    , decay=rate_decay_learning\n","                )\n","    opt_sgd = keras.optimizers.SGD(\n","                    lr=rate_learning\n","                    , decay=rate_decay_learning\n","                    , momentum=0.9\n","                    , nesterov=False\n","                )\n","    optimizers ={\n","        \"adam\":opt_adam\n","        ,\"rmsprop\":opt_rms\n","        ,\"sgd\":opt_sgd\n","    }\n","    \n","    model_bilinear.compile(\n","        loss=name_loss\n","        , optimizer=optimizers[name_optimizer]\n","        , metrics=[\"categorical_accuracy\"]\n","    )\n","    \n","    \n","    \n","    if flg_debug:\n","        model_bilinear.summary()\n","    \n","    return model_bilinear"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zwdbn6up_yL-","colab_type":"code","colab":{}},"source":["# Model compiling.\n","model = build_model(\n","            # number of output classes\n","            no_class = 8\n","\n","            # pretrained model specification, using VGG16\n","            # \"block5_conv3 \"\n","            ,no_last_layer_backbone = 17\n","    \n","            # training parametes\n","            ,rate_learning=1.0\n","            ,rate_decay_weight=1e-8\n","    \n","            ,flg_debug=True\n","        )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9RN0hZ1KAeGG","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","model_checkpoint = ModelCheckpoint('vgg-Bilinearnet.h5', monitor='loss', verbose=1, save_best_only=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2W7lwdMeghBZ","colab_type":"code","colab":{}},"source":["# Training only the classification layer.\n","history=model.fit(X_train, Y_train, batch_size=50, epochs=50, verbose=1,\n","          validation_data=(X_test, Y_test),callbacks=[model_checkpoint])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODTJMx7WSUTR","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","from keras.models import Sequential, Model\n","model.load_weights('vgg-Bilinearnet.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8HwarbEX4Ka0","colab_type":"code","colab":{}},"source":["# now all layers are trainable\n","for layer in model.layers:\n","    layer.trainable = True\n","\n","# change LR\n","opt_sgd = keras.optimizers.SGD(\n","                lr=1e-3\n","                , decay=1e-9\n","                , momentum=0.9\n","                , nesterov=False\n","            )\n","model.compile(\n","    loss=\"categorical_crossentropy\"\n","    , optimizer=opt_sgd\n","    , metrics=[\"categorical_accuracy\"]\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmZHebhF-MUv","colab_type":"code","colab":{}},"source":["# Train the entire model.\n","history=model.fit(X_train, Y_train, batch_size=50, epochs=100, verbose=1,\n","          validation_data=(X_test, Y_test),callbacks=[model_checkpoint])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bz8aQJktW7R6","colab_type":"code","colab":{}},"source":["# Draw a graph of accuracy and loss functions.\n","print(history.history.keys())\n","\n","# summarize history for accuracy\n","plt.plot(history.history['categorical_accuracy'])\n","plt.plot(history.history['val_categorical_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]}]}