{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test-WRN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AkuKJUawq-D-","colab_type":"text"},"source":["*   Author : Ziang Xu\n","*   Student number : 180104048\n","*   Code : WRN model construction, training and testing."]},{"cell_type":"code","metadata":{"id":"YOdrjACo-HAq","colab_type":"code","colab":{}},"source":["# Google Colaboratory carry Google drive\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjN3w2s6-jp9","colab_type":"code","colab":{}},"source":["# Enter the classification task directory.\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"drive/ML/classification/\")\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wawUphaR_EKj","colab_type":"code","colab":{}},"source":["# Read dataset\n","import os\n","import numpy as np\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt\n","images=[]\n","labels=[]\n","def read_image(imageName):\n","    im = Image.open(imageName).convert('RGB')\n","    data = np.array(im)\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVWNUV3O_FZq","colab_type":"code","colab":{}},"source":["# Read there are several folders in the dataset.\n","text = os.listdir('./resize_data')\n","# Save the name of the image in the folder and its corresponding folder to the corresponding list.\n","for textPath in text:\n","    for fn in os.listdir(os.path.join('resize_data', textPath)):\n","        if fn.endswith('.jpg'):\n","            fd = os.path.join('./resize_data', textPath, fn)\n","            images.append(read_image(fd))\n","            labels.append(textPath)\n","            \n","X = np.array(images)\n","y = np.array(list(map(int, labels)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BfQ9OpABPXVE","colab_type":"code","colab":{}},"source":["# Split dataset to 0.8 for training and 0.2 for testing.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=30)\n","# Normalized dataset\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","from keras.utils import np_utils\n","Y_train = np_utils.to_categorical(y_train, 8)\n","Y_test = np_utils.to_categorical(y_test, 8)\n","\n","print(X_train.shape)\n","print(Y_train.shape)\n","print(X_test.shape)\n","print(Y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q3YnOUbkO0qo","colab_type":"code","colab":{}},"source":["# Model building.\n","from keras.models import Model\n","from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras import backend as K\n","\n","\n","def initial_conv(input):\n","    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n","                      use_bias=False)(input)\n","\n","    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n","    x = Activation('relu')(x)\n","    return x\n","\n","\n","def expand_conv(init, base, k, strides=(1, 1)):\n","    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal',\n","                      use_bias=False)(init)\n","\n","    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n","    x = Activation('relu')(x)\n","\n","    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n","                      use_bias=False)(x)\n","\n","    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n","                      use_bias=False)(init)\n","\n","    m = Add()([x, skip])\n","\n","    return m\n","def conv1_block(input, k=1, dropout=0.0):\n","    init = input\n","\n","    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n","    x = Activation('relu')(x)\n","    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n","                      use_bias=False)(x)\n","\n","    if dropout > 0.0: x = Dropout(dropout)(x)\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n","    x = Activation('relu')(x)\n","    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n","                      use_bias=False)(x)\n","\n","    m = Add()([init, x])\n","    return m\n","\n","def conv2_block(input, k=1, dropout=0.0):\n","    init = input\n","\n","    channel_axis = 1 if K.image_dim_ordering() == \"th\" else -1\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n","    x = Activation('relu')(x)\n","    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n","                      use_bias=False)(x)\n","\n","    if dropout > 0.0: x = Dropout(dropout)(x)\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n","    x = Activation('relu')(x)\n","    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n","                      use_bias=False)(x)\n","\n","    m = Add()([init, x])\n","    return m\n","\n","def conv3_block(input, k=1, dropout=0.0):\n","    init = input\n","\n","    channel_axis = 1 if K.image_dim_ordering() == \"th\" else -1\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n","    x = Activation('relu')(x)\n","    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n","                      use_bias=False)(x)\n","\n","    if dropout > 0.0: x = Dropout(dropout)(x)\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n","    x = Activation('relu')(x)\n","    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n","                      use_bias=False)(x)\n","\n","    m = Add()([init, x])\n","    return m\n","\n","def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n","    \"\"\"\n","    Creates a Wide Residual Network with specified parameters\n","    :param input: Input Keras object\n","    :param nb_classes: Number of output classes\n","    :param N: Depth of the network. Compute N = (n - 4) / 6.\n","              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n","              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n","              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n","    :param k: Width of the network.\n","    :param dropout: Adds dropout if value is greater than 0.0\n","    :param verbose: Debug info to describe created WRN\n","    :return:\n","    \"\"\"\n","    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n","\n","    ip = Input(shape=input_dim)\n","\n","    x = initial_conv(ip)\n","    nb_conv = 4\n","\n","    x = expand_conv(x, 16, k)\n","\n","    for i in range(N - 1):\n","        x = conv1_block(x, k, dropout)\n","        nb_conv += 2\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n","    x = Activation('relu')(x)\n","\n","    x = expand_conv(x, 32, k, strides=(2, 2))\n","\n","    for i in range(N - 1):\n","        x = conv2_block(x, k, dropout)\n","        nb_conv += 2\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n","    x = Activation('relu')(x)\n","\n","    x = expand_conv(x, 64, k, strides=(2, 2))\n","\n","    for i in range(N - 1):\n","        x = conv3_block(x, k, dropout)\n","        nb_conv += 2\n","\n","    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n","    x = Activation('relu')(x)\n","\n","    x = AveragePooling2D((8, 8))(x)\n","    x = Flatten()(x)\n","\n","    x = Dense(nb_classes, activation='softmax')(x)\n","\n","    model = Model(ip, x)\n","\n","    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GrRynokWPABX","colab_type":"code","colab":{}},"source":["# WRN-28-10 building.\n","if __name__ == \"__main__\":\n","    from keras.utils import plot_model\n","    from keras.layers import Input\n","    from keras.models import Model\n","    init = (224, 224, 3)\n","    wrn_28_10 = create_wide_residual_network(init, nb_classes=8, N=2, k=2, dropout=0.0)\n","\n","    wrn_28_10.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rXE0oTxnPNK7","colab_type":"code","colab":{}},"source":["# Customize the optimizer and compile the model.\n","from keras.optimizers import SGD\n","sgd = SGD(lr=0.01, decay=1e-5)\n","wrn_28_10.compile(optimizer=sgd, loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ixoh5jj_PUZ0","colab_type":"code","colab":{}},"source":["# Training\n","print('Training begin')\n","history=wrn_28_10.fit(X_train, Y_train, batch_size=50, epochs=100,validation_data=(X_test, Y_test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nas3J0a2QRQW","colab_type":"code","colab":{}},"source":["# Model saving and loading.\n","wrn_28_10.save('model3.h5')\n","from keras.models import load_model\n","model=load_model('model3.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_qyruTHQCzb","colab_type":"code","colab":{}},"source":["# Draw a graph of accuracy and loss functions.\n","print(history.history.keys())\n","\n","# summarize history for accuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"j9R55S9NQQE0","colab_type":"code","colab":{}},"source":["# Model evaluation\n","print('Model evaluation')\n","scores = model.evaluate(X_test, Y_test)\n","print('Test score:', scores[0])\n","print('Test accuracy:', scores[1])"],"execution_count":0,"outputs":[]}]}