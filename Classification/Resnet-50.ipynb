{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_Resnet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"C1uzgr_vpSAE","colab_type":"text"},"source":["*   Author : Ziang Xu\n","*   Student number : 180104048\n","*   Code : Resnet-50 model construction, training and testing.\n","*   Grad-CAM Visualization."]},{"cell_type":"code","metadata":{"id":"niQinA_8Gd-q","colab_type":"code","colab":{}},"source":["# Google Colaboratory carry Google drive\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"URDewj11ITIv","colab_type":"code","colab":{}},"source":["# Enter the classification task directory\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","import os\n","os.chdir(\"drive/ML/classification/\")\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cOtLnbQWHyFf","colab_type":"code","colab":{}},"source":["!pip uninstall tensorflow\n","!pip uninstall keras\n","!pip uninstall keras-vis\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"skoq_L0Nt1qr","colab_type":"code","colab":{}},"source":["!pip install keras\n","!pip install tensorflow==1.12\n","!pip install git+https://github.com/raghakot/keras-vis.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OClj5HzFHO46","colab_type":"code","colab":{}},"source":["# Read dataset\n","import os\n","import numpy as np\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt\n","images=[]\n","labels=[]\n","def read_image(imageName):\n","    im = Image.open(imageName).convert('RGB')\n","    data = np.array(im)\n","    return data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NTQclJPgHUDI","colab_type":"code","colab":{}},"source":["# Read there are several folders in the dataset.\n","text = os.listdir('./resize_data')\n","# Save the name of the image in the folder and its corresponding folder to the corresponding list.\n","for textPath in text:\n","    for fn in os.listdir(os.path.join('resize_data', textPath)):\n","        if fn.endswith('.jpg'):\n","            fd = os.path.join('./resize_data', textPath, fn)\n","            images.append(read_image(fd))\n","            labels.append(textPath)\n","X = np.array(images)\n","y = np.array(list(map(int, labels)))             \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThCRsqGHP2dA","colab_type":"code","colab":{}},"source":["# Split dataset to 0.8 for training and 0.2 for testing.\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=30)\n","# Normalized dataset\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255\n","from keras.utils import np_utils\n","Y_train = np_utils.to_categorical(y_train, 8)\n","Y_test = np_utils.to_categorical(y_test, 8)\n","\n","print(X_train.shape)\n","print(Y_train.shape)\n","print(X_test.shape)\n","print(Y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3KF44eninaMp","colab_type":"code","colab":{}},"source":["# Fine-tuning technique is used to build model.\n","from keras.applications.resnet50 import ResNet50\n","from keras.layers import Input\n","from keras.layers import Flatten\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.models import Model\n","from keras.optimizers import SGD\n","\n","base_model = ResNet50(weights = 'imagenet',include_top = False,pooling = 'avg',\n","                      input_shape=(224, 224, 3))\n","\n","\n","predictions = Dense(4096, activation='relu')(base_model.output)\n","predictions = Dense(4096, activation='relu')(base_model.output)\n","predictions = Dropout(0.5)(predictions)\n","predictions = Dense(8, activation='softmax')(predictions)\n","\n","\n","\n","model = Model(inputs=base_model.input, outputs=predictions, name='Resnet50')\n","sgd = SGD(lr=0.01, decay=1e-5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GkSRrSghozHy","colab_type":"code","colab":{}},"source":["# Compile the model.\n","model.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ph-PhDqpL1o","colab_type":"code","colab":{}},"source":["print('Training begin')\n","history=model.fit(X_train, y_train, batch_size=50, epochs=100,validation_data=(X_test, Y_test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XSuoAq7ZxQA1","colab_type":"code","colab":{}},"source":["# Draw a graph of accuracy and loss functions.\n","print(history.history.keys())\n","\n","# summarize history for accuracy\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9TlE5NqxUh_","colab_type":"code","colab":{}},"source":["# Model saving and loading.\n","# model.save('model2.h5')\n","from keras.models import load_model\n","model=load_model('model2.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DN48eE41bjR5","colab_type":"code","colab":{}},"source":["# Model visualization\n","from keras.applications import ResNet50\n","from vis.utils import utils\n","from keras import activations\n","\n","# Hide warnings on Jupyter Notebook\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","layer_idx = utils.find_layer_idx(model, 'dense_5')\n","\n","model.layers[layer_idx].activation = activations.linear\n","model = utils.apply_modifications(model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzEajEqabyop","colab_type":"code","colab":{}},"source":["from vis.utils import utils\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","plt.rcParams['figure.figsize'] = (18, 6)\n","\n","img1 = utils.load_img('image/1.jpg', target_size=(224, 224))\n","f, ax = plt.subplots(1, 1)\n","ax.imshow(img1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ONUW3E29HsHC","colab_type":"code","colab":{}},"source":["from vis.visualization import visualize_saliency, overlay\n","from vis.utils import utils\n","from keras import activations\n","\n","# Utility to search for layer index by name. \n","# Alternatively we can specify this as -1 since it corresponds to the last layer.\n","layer_idx = utils.find_layer_idx(model, 'dense_5')\n","\n","f, ax = plt.subplots(1, 1)  \n","\n","grads = visualize_saliency(model, layer_idx, filter_indices=0, seed_input=img1)\n","    \n","# visualize grads as heatmap\n","ax.imshow(grads, cmap='jet')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"25fKMbwDNF20","colab_type":"code","colab":{}},"source":["for modifier in ['guided', 'relu']:\n","    plt.figure()\n","    f, ax = plt.subplots(1, 1)\n","    plt.suptitle(modifier)\n","       \n","    \n","    grads = visualize_saliency(model, layer_idx, filter_indices=0, \n","                                   seed_input=img1, backprop_modifier=modifier)\n","    # Lets overlay the heatmap onto original image.    \n","    ax.imshow(grads, cmap='jet')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UiKHyxkcLFDr","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.cm as cm\n","from vis.visualization import visualize_cam\n","\n","penultimate_layer = utils.find_layer_idx(model, 'res5c_branch2c')\n","\n","for modifier in [None, 'guided', 'relu']:\n","    plt.figure()\n","    f, ax = plt.subplots(1, 1)\n","    plt.suptitle(\"vanilla\" if modifier is None else modifier)\n","      \n","    # 0 is the imagenet index corresponding to `dyed-lifted-polyps`\n","    grads = visualize_cam(model, layer_idx, filter_indices=0, \n","                              seed_input=img1, penultimate_layer_idx=penultimate_layer,\n","                              backprop_modifier=modifier)        \n","    # Lets overlay the heatmap onto original image.    \n","    jet_heatmap = np.uint8(cm.jet(grads)[..., :3] * 255)\n","    ax.imshow(overlay(jet_heatmap, img1))"],"execution_count":0,"outputs":[]}]}